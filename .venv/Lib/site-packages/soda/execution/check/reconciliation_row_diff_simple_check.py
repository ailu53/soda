from __future__ import annotations

import time

from soda.execution.check.reconciliation_row_diff_check import (
    ReconciliationRowDiffCheck,
)
from soda.execution.compare.value_comparator import ValueComparator
from soda.execution.metric.metric import Metric
from soda.execution.metric.reconciliation_row_count_metric import (
    ReconciliationRowCountMetric,
)
from soda.sampler.in_memory_sample import InMemorySample
from soda.sampler.sample_context import SampleContext
from soda.sampler.sampler import Sampler
from soda.sodacl.reconciliation_row_diff_check_cfg import ReconciliationRowDiffCheckCfg


class ReconciliationRowDiffSimpleCheck(ReconciliationRowDiffCheck):
    def __init__(
        self, check_cfg: ReconciliationRowDiffCheckCfg, data_source_scan: DataSourceScan, partition: Partition
    ):
        super().__init__(check_cfg=check_cfg, data_source_scan=data_source_scan, partition=partition)

        source_metric = ReconciliationRowCountMetric(
            data_source_scan=self.source_data_source_scan,
            check=self,
            partition=self.source_partition,
            filter=self.source_filter,
        )
        target_metric = ReconciliationRowCountMetric(
            data_source_scan=self.target_data_source_scan,
            check=self,
            partition=self.target_partition,
            filter=self.target_filter,
        )

        self.src_sql = self.source_data_source_scan.data_source.sql_select_all(
            table_name=self.source_table.table_name,
            columns=self.src_columns,
            filter=self.source_filter,
            order_by=self.source_key_columns,
        )
        self.tgt_sql = self.target_data_source_scan.data_source.sql_select_all(
            table_name=self.target_table.table_name,
            columns=self.tgt_columns,
            filter=self.target_filter,
            order_by=self.target_key_columns,
        )

        self.metrics["source_metric"] = self.source_data_source_scan.resolve_metric(source_metric)
        self.metrics["target_metric"] = self.target_data_source_scan.resolve_metric(target_metric)

    def evaluate(self, metrics: dict[str, Metric], historic_values: dict[str, object]):
        value_comparator: ValueComparator = self.data_source_scan.scan.value_comparator

        if (
            self.source_data_source_scan.data_source.data_source_name
            == self.target_data_source_scan.data_source.data_source_name
        ):
            self.check_value = None
            self.logs.error(
                f"Cannot evaluate '{self.name}' check. Two separate data sources are required for '{self.check_cfg.strategy}' strategy.'"
            )
            return

        if not self.source_key_columns or not self.target_key_columns:
            self.check_value = None
            self.logs.error(
                f"Cannot evaluate '{self.name}' check. Valid key columns configuration is required for '{self.check_cfg.strategy}' strategy.'"
            )
            return

        total_query_time = 0
        total_diff_time = 0

        def result_iterator(cursor, data_source, sql: str, total_rows: int, page_size=1, batch_size=1):
            nonlocal total_query_time
            nonlocal total_diff_time

            total_pages = (total_rows // page_size) + (total_rows % page_size > 0)

            for page in range(total_pages):
                offset = page * page_size
                start_time = time.time()
                paginated_sql = data_source.sql_paginate_query(sql, offset, page_size)

                self.logs.debug(f"Page {page}:\\query:\n{paginated_sql}")
                cursor.execute(paginated_sql)
                sql_time = time.time() - start_time

                total_query_time += sql_time
                self.logs.debug(f"Intermediate SQL TIME: {total_query_time}")

                # Page diffing starts here.
                start_time = time.time()
                for _ in range(0, page_size, batch_size):
                    results = cursor.fetchmany(batch_size)

                    if not results:
                        break
                    yield from results

                diff_time = time.time() - start_time
                total_diff_time += diff_time
                self.logs.debug(f"Intermediate DIFF TIME: {total_diff_time}")

        src_data_source = self.source_data_source_scan.data_source
        src_cursor = src_data_source.connection.cursor()

        tgt_data_source = self.target_data_source_scan.data_source
        tgt_cursor = tgt_data_source.connection.cursor()

        page_size = self.check_cfg.page_size
        batch_size = self.check_cfg.batch_size

        self.logs.debug(f"Page size: {page_size}")
        self.logs.debug(f"Batch size: {batch_size}")

        src_total_rows = self.metrics["source_metric"].value
        tgt_total_rows = self.metrics["target_metric"].value

        diff = {
            self.CHANGED: [],
            self.ADDED: [],
            self.REMOVED: [],
            self.METADATA: {self.COLUMNS: {}},
        }

        src_advance = True
        tgt_advance = True

        src_columns = []
        src_key_columns_indexes = []
        tgt_columns = []
        tgt_key_columns_indexes = []

        src_iterator = result_iterator(src_cursor, src_data_source, self.src_sql, src_total_rows, page_size, batch_size)
        tgt_iterator = result_iterator(tgt_cursor, tgt_data_source, self.tgt_sql, tgt_total_rows, page_size, batch_size)

        while True:
            row_diff = {}

            if src_advance:
                try:
                    src_row = next(src_iterator)
                except StopIteration:
                    src_row = None
                    src_advance = False
            if tgt_advance:
                try:
                    tgt_row = next(tgt_iterator)
                except StopIteration:
                    tgt_row = None
                    tgt_advance = False

            if not src_row and not tgt_row:
                break

            if src_row:
                if not src_columns or not src_key_columns_indexes:
                    src_columns = [desc[0] for desc in src_cursor.description]
                    src_key_columns_indexes = [src_columns.index(key) for key in self.source_key_columns]

                src_key_parts = []
                for index in src_key_columns_indexes:
                    src_key_parts.append(src_row[index])

            if tgt_row:
                if not tgt_columns or not tgt_key_columns_indexes:
                    tgt_columns = [desc[0] for desc in tgt_cursor.description]
                    tgt_key_columns_indexes = [tgt_columns.index(key) for key in self.target_key_columns]

                tgt_key_parts = []
                for index in tgt_key_columns_indexes:
                    tgt_key_parts.append(tgt_row[index])

            if len(src_columns) != len(tgt_columns):
                self.check_value = None
                self.logs.error(f"Cannot evaluate '{self.name}' check. Target and source schemas are not similar.")
                return

            if src_row and tgt_row and src_key_parts == tgt_key_parts:
                src_advance = True
                tgt_advance = True
                row_diff = {self.CHANGED: {}}

                for i in range(len(src_row)):
                    if not value_comparator.equals(src_row[i], tgt_row[i]):
                        column_name = src_columns[i]
                        if src_columns[i] != tgt_columns[i]:
                            column_name = f"{src_columns[i]} -> {tgt_columns[i]}"

                        row_diff[self.CHANGED][column_name] = {"old_value": src_row[i], "new_value": tgt_row[i]}

                        if column_name not in diff[self.METADATA][self.COLUMNS]:
                            diff[self.METADATA][self.COLUMNS][column_name] = {self.CHANGED: 0}
                        diff[self.METADATA][self.COLUMNS][column_name][self.CHANGED] += 1
                if row_diff[self.CHANGED]:
                    # Src and tgt key(parts) are the same, so we can use either one.
                    row_diff["key_parts"] = src_key_parts
                    diff[self.CHANGED].append(row_diff)

            if (src_row and not tgt_row) or ((src_row and tgt_row) and (src_key_parts < tgt_key_parts)):
                row_diff["key_parts"] = src_key_parts
                src_advance = True
                tgt_advance = False
                diff[self.REMOVED].append(row_diff)

            if (not src_row and tgt_row) or ((src_row and tgt_row) and (src_key_parts > tgt_key_parts)):
                row_diff["key_parts"] = tgt_key_parts
                src_advance = False
                tgt_advance = True
                diff[self.ADDED].append(row_diff)

        self.logs.debug(f"TOTAL QUERY TIME: {total_query_time}")
        self.logs.debug(f"TOTAL DIFF TIME: {total_diff_time}")

        changed = 0
        added = 0
        removed = 0

        from soda.scan import verbose

        if verbose:
            from pprint import pprint

            pprint(diff)

        if diff:
            allow_samples = True
            src_offending_columns = []
            tgt_offending_columns = []

            src_tgt_cols = []
            for i in range(0, len(self.source_key_columns)):
                if self.source_key_columns[i] == self.target_key_columns[i]:
                    column_header = self.source_key_columns[i]
                else:
                    column_header = f"{self.source_key_columns[i]} -> {self.target_key_columns[i]}"
                src_tgt_cols.append(column_header)
            samples_schema = src_tgt_cols + ["event", "column", "source", "target"]
            samples = []

            is_column_excluded = self.data_source_scan.data_source.is_column_excluded
            src_table = self.metrics["source_metric"].partition.table.table_name
            tgt_table = self.metrics["target_metric"].partition.table.table_name

            for src_column in src_columns:
                if is_column_excluded(src_table, src_column):
                    src_offending_columns.append(src_column)
                    allow_samples = False

            for tgt_column in tgt_columns:
                if is_column_excluded(tgt_table, tgt_column):
                    tgt_offending_columns.append(tgt_column)
                    allow_samples = False

            if self.CHANGED in diff:
                changed = len(diff[self.CHANGED])
                for row_diff in diff[self.CHANGED]:
                    for row in self._diff_changed_to_sample(
                        row_diff,
                    ):
                        self.add_to_samples(samples, row)

            if self.ADDED in diff:
                added = len(diff[self.ADDED])

                for row_diff in diff[self.ADDED]:
                    self.add_to_samples(samples, self._diff_added_to_sample(row_diff))

            if self.REMOVED in diff:
                removed = len(diff[self.REMOVED])

                for row_diff in diff[self.REMOVED]:
                    self.add_to_samples(samples, self._diff_removed_to_sample(row_diff))

            if allow_samples and samples:
                sampler: Sampler = self.data_source_scan.scan._configuration.sampler
                sample_context = SampleContext(
                    sample=InMemorySample(samples, samples_schema, data_source=self.data_source_scan.data_source),
                    sample_name="failed rows",
                    query="",
                    data_source=self.data_source_scan.data_source,
                    partition=self.partition,
                    column=None,
                    scan=self.data_source_scan.scan,
                    logs=self.data_source_scan.scan._logs,
                    samples_limit=self.check_cfg.samples_limit,
                    passing_sql="",
                    check_name=self.name,
                )

                self.failed_rows_sample_ref = sampler.store_sample(sample_context)

        self.check_value = changed + added + removed
        self.set_outcome_based_on_check_value()

        self.outcome_dict = {
            "changed": changed,
            "exclusive_in_target": added,
            "exclusive_in_source": removed,
            "source_count": src_total_rows,
            "target_count": tgt_total_rows,
        }

        if diff[self.METADATA][self.COLUMNS]:
            for column, metadata in diff[self.METADATA][self.COLUMNS].items():
                self.outcome_dict[f"changes_in_{column}"] = metadata[self.CHANGED]

    def _diff_changed_to_sample(self, row_diff: dict) -> list[list[str]]:
        # Turns a row diff into as many sample rows as there are changed columns. Returns a list of sample rows.
        samples = []

        # Build up the "base" of a sample row using shared values.
        sample_base = [*row_diff["key_parts"], "Changed"]

        for column, values in row_diff["changed"].items():
            samples.append([*sample_base, column, values["old_value"], values["new_value"]])

        return samples

    def _diff_added_to_sample(self, row_diff: dict) -> list[str]:
        # Turns a row diff into a sample row.
        return [*row_diff["key_parts"], "Exclusive in target", "", "", ""]

    def _diff_removed_to_sample(self, row_diff: dict) -> list[str]:
        # Turns a row diff into a sample row.
        return [*row_diff["key_parts"], "Exclusive in source", "", "", ""]
