from __future__ import annotations

import json
import logging
import tempfile
from datetime import date, datetime, timedelta, timezone
from time import sleep
from typing import TYPE_CHECKING

from requests import Response
from soda_library.__version__ import SODA_LIBRARY_VERSION

from soda.cloud.cloud import Cloud
from soda.cloud.historic_descriptor import (
    HistoricChangeOverTimeDescriptor,
    HistoricCheckResultsDescriptor,
    HistoricDescriptor,
    HistoricMeasurementsDescriptor,
)
from soda.common.datetime_helper import datetime_from_iso_zulu
from soda.common.json_helper import JsonHelper
from soda.common.log import Log
from soda.common.logs import Logs
from soda.execution.check_type import CheckType
from soda.execution.scan_result import ScanResult

logger = logging.getLogger(__name__)

if TYPE_CHECKING:
    from soda.scan import Scan

from enum import Enum


class RemoteScanStatus(Enum):
    QUEUING = "queuing"
    EXECUTING = "executing"
    CANCELATION_REQUESTED = "cancelationRequested"
    TIME_OUT_REQUESTED = "timeOutRequested"
    CANCELED = "canceled"
    TIMED_OUT = "timedOut"
    FAILED = "failed"
    COMPLETED_WITH_ERRORS = "completedWithErrors"
    COMPLETED_WITH_FAILURES = "completedWithFailures"
    COMPLETED_WITH_WARNINGS = "completedWithWarnings"
    COMPLETED = "completed"


REMOTE_SCAN_CLOUD_MAPPING = {i.value: i for i in RemoteScanStatus}

REMOTE_SCAN_RUNNING_STATES = [
    RemoteScanStatus.QUEUING,
    RemoteScanStatus.EXECUTING,
    RemoteScanStatus.CANCELATION_REQUESTED,
    RemoteScanStatus.TIME_OUT_REQUESTED,
]
REMOTE_SCAN_FINAL_STATES = [
    RemoteScanStatus.CANCELED,
    RemoteScanStatus.TIMED_OUT,
    RemoteScanStatus.FAILED,
    RemoteScanStatus.COMPLETED_WITH_ERRORS,
    RemoteScanStatus.COMPLETED_WITH_FAILURES,
    RemoteScanStatus.COMPLETED_WITH_WARNINGS,
    RemoteScanStatus.COMPLETED,
]
REMOTE_SCAN_COMPLETED_STATES = [
    RemoteScanStatus.COMPLETED_WITH_ERRORS,
    RemoteScanStatus.COMPLETED_WITH_FAILURES,
    RemoteScanStatus.COMPLETED_WITH_WARNINGS,
    RemoteScanStatus.COMPLETED,
]
REMOTE_SCAN_ERROR_STATES = [
    RemoteScanStatus.CANCELED,
    RemoteScanStatus.TIMED_OUT,
    RemoteScanStatus.FAILED,
]


class SodaCloud(Cloud):
    ORG_CONFIG_KEY_DISABLE_COLLECTING_WH_DATA = "disableCollectingWarehouseData"

    CSV_TEXT_MAX_LENGTH = 1500

    def __init__(
        self,
        host: str,
        api_key_id: str,
        api_key_secret: str,
        token: str | None,
        port: str | None,
        logs: Logs,
        scheme: str = "https",
    ):
        self.host = host
        self.port = f":{port}" if port else ""
        self.scheme = scheme if scheme else "https"
        self.cloud_url = f"{self.scheme}://{self.host}{self.port}"
        self.api_url = f"{self.cloud_url}/api"
        self.api_key_id = api_key_id
        self.api_key_secret = api_key_secret
        self.token: str | None = token
        self.headers = {"User-Agent": f"SodaLibrary/{SODA_LIBRARY_VERSION}"}
        self.logs = logs
        self.soda_cloud_trace_ids = {}
        self._organization_configuration = None
        self.org_id: str | None = None
        self.organization_info: dict | None = None
        self.user: dict | None = None

    @property
    def organization_configuration(self) -> dict:
        if isinstance(self._organization_configuration, dict):
            return self._organization_configuration

        response_json_dict = self._execute_query(
            {"type": "sodaCoreCloudConfiguration"},
            query_name="get_organization_configuration",
        )
        self._organization_configuration = response_json_dict if isinstance(response_json_dict, dict) else {}

        return self._organization_configuration

    @staticmethod
    def build_scan_results(scan: Scan, metadata: dict = {}) -> dict:
        checks = [
            check.get_cloud_dict()
            for check in scan._checks
            if check.check_type == CheckType.CLOUD
            and (check.outcome is not None or check.force_send_results_to_cloud is True)
            and check.archetype is None
        ]
        automated_monitoring_checks = [
            check.get_cloud_dict()
            for check in scan._checks
            if (check.outcome is not None or check.force_send_results_to_cloud is True) and check.archetype is not None
        ]

        # TODO: [SODA-608] separate profile columns and sample tables by aligning with the backend team
        profiling = [
            profile_table.get_cloud_dict()
            for profile_table in scan._profile_columns_result_tables + scan._sample_tables_result_tables
        ]

        query_list = []
        for query in scan._queries:
            query_list += query.get_cloud_dicts()

        body = {
            "scanReference": metadata["scanReference"] if "scanReference" in metadata else None,
            "cloudUrl": scan._configuration.soda_cloud.cloud_url,
            "definitionName": scan._scan_definition_name,
            "defaultDataSource": scan._data_source_name,
            "dataTimestamp": scan._data_timestamp,
            # Can be changed by user, this is shown in Cloud as time of a scan.
            "scanStartTimestamp": scan._scan_start_timestamp,  # Actual time when the scan started.
            "scanEndTimestamp": scan._scan_end_timestamp,  # Actual time when scan ended.
            "hasErrors": scan.has_error_logs(),
            "hasWarnings": scan.has_check_warns(),
            "hasFailures": scan.has_check_fails(),
            "metrics": [metric.get_cloud_dict() for metric in scan._metrics],
            # If archetype is not None, it means that check is automated monitoring
            "checks": checks,
            "checksMetadata": metadata["checks"] if "checks" in metadata else {},
            "queries": query_list,
            "automatedMonitoringChecks": automated_monitoring_checks,
            "profiling": profiling,
            "ciInfo": scan._ci_info,
            "scanType": scan._scan_type,
            "metadata": [
                discover_tables_result.get_cloud_dict()
                for discover_tables_result in scan._discover_tables_result_tables
            ],
            "logs": [log.get_cloud_dict() for log in scan._logs.logs],
            "sourceOwner": "soda-library",
            "discussion": scan._discussion,
            "scanId": scan._scan_id,
        }

        data_source_scan = scan._get_or_create_data_source_scan(scan._data_source_name)
        if data_source_scan:
            default_data_source = data_source_scan.data_source
            body["defaultDataSourceProperties"] = default_data_source.get_basic_properties()

        return JsonHelper.to_jsonnable(body)

    def login(self) -> tuple(int, dict):
        login_command = {"type": "login"}
        if self.api_key_id and self.api_key_secret:
            login_command["apiKeyId"] = self.api_key_id
            login_command["apiKeySecret"] = self.api_key_secret
        else:
            raise RuntimeError("No API KEY and/or SECRET provided ")

        login_response = self._http_post(
            url=f"{self.api_url}/command", headers=self.headers, json=login_command, request_name="get_token"
        )
        login_response_json = login_response.json()

        return login_response.status_code, login_response_json

    def who_am_i(self) -> tuple(int, dict):
        query = {"type": "whoAmI"}
        query["token"] = self._get_token()

        response = self._http_post(
            url=f"{self.api_url}/query", headers=self.headers, json=query, request_name="who_am_i"
        )
        response_json = response.json()

        return response.status_code, response_json

    def upload_sample(
        self, scan: Scan, sample_rows: tuple[tuple], sample_file_name: str, samples_limit: int | None
    ) -> str:
        """
        :param sample_file_name: file name without extension
        :return: Soda Cloud file_id
        """
        if scan._is_local:
            self.logs.info("Skipping upload sample to Soda Cloud, because scan is local")
            return ""
        else:
            self.logs.info(f"Sending failed row samples to Soda Cloud")

        # Keep the interface of this method backward compatible and allow for samples limit to be None, but do not continue with no limit in such case.
        if not samples_limit:
            samples_limit = 100

        try:
            scan_definition_name = scan._scan_definition_name
            scan_data_timestamp = scan._data_timestamp
            scan_folder_name = (
                f"{self._fileify(scan_definition_name)}"
                f'_{scan_data_timestamp.strftime("%Y%m%d%H%M%S")}'
                f'_{datetime.now(tz=timezone.utc).strftime("%Y%m%d%H%M%S")}'
            )

            with tempfile.TemporaryFile() as temp_file:
                for row in sample_rows[0:samples_limit]:
                    row = [self._serialize_file_upload_value(v) for v in row]
                    rows_json_str = json.dumps(row)
                    rows_json_bytes = bytearray(rows_json_str, "utf-8")
                    temp_file.write(rows_json_bytes)
                    temp_file.write(b"\n")

                temp_file_size_in_bytes = temp_file.tell()
                temp_file.seek(0)

                file_path = f"{scan_folder_name}/" + f"{sample_file_name}.jsonl"

                file_id = self._upload_sample_http(scan_definition_name, file_path, temp_file, temp_file_size_in_bytes)

                return file_id

        except Exception as e:
            self.logs.error(f"Soda cloud error: Could not upload sample {sample_file_name}", exception=e)

    def _upload_sample_http(self, scan_definition_name: str, file_path, temp_file, file_size_in_bytes: int):
        headers = {
            "Authorization": self._get_token(),
            "Content-Type": "application/octet-stream",
            "Is-V3": "true",
            "File-Path": file_path,
        }

        if file_size_in_bytes == 0:
            # because of https://github.com/psf/requests/issues/4215 we can't send content size
            # when the size is 0 since requests blocks then on I/O indefinitely
            self.logs.warning("Empty file upload detected, not sending Content-Length header")
        else:
            headers["Content-Length"] = str(file_size_in_bytes)

        upload_response = self._http_post(url=f"{self.api_url}/scan/upload", headers=headers, data=temp_file)
        upload_response_json = upload_response.json()

        if "fileId" not in upload_response_json:
            logger.error(f"No fileId received in response: {upload_response_json}")
            return None
        else:
            return upload_response_json["fileId"]

    def send_scan_results(self, scan: Scan, metadata: dict = {}):
        scan_results = self.build_scan_results(scan, metadata)
        scan_results["type"] = "sodaCoreInsertScanResults"

        if scan._is_local:
            self.logs.info("Skipping sending scan results to Soda Cloud, because scan is local")
            return

        return self._execute_command(scan_results, command_name="send_scan_results")

    def get_historic_data(self, historic_descriptor: HistoricDescriptor):
        measurements = {}
        check_results = {}

        if type(historic_descriptor) == HistoricMeasurementsDescriptor:
            measurements = self._get_historic_measurements(historic_descriptor)
        elif type(historic_descriptor) == HistoricCheckResultsDescriptor:
            check_results = self._get_historic_check_results(historic_descriptor)
        elif type(historic_descriptor) == HistoricChangeOverTimeDescriptor:
            measurements = self._get_historic_changes_over_time(historic_descriptor)
        else:
            logger.error(f"Invalid Historic Descriptor provided {historic_descriptor}")

        return {"measurements": measurements, "check_results": check_results}

    def is_samples_disabled(self) -> bool:
        return self.organization_configuration.get(self.ORG_CONFIG_KEY_DISABLE_COLLECTING_WH_DATA, True)

    def get_check_attributes_schema(self) -> list(dict):
        response_json_dict = self._execute_query(
            {"type": "sodaCoreAvailableCheckAttributes"},
            query_name="get_check_attributes",
        )

        if response_json_dict and "results" in response_json_dict:
            return response_json_dict["results"]

        return []

    def start_remote_scan(self, scan_definition_name: str, remote_mode: str) -> dict:
        response, _ = self._execute_request(
            path="v1/scans",
            request_name=f"remote-scan-start-{remote_mode}",
            request_data={
                "scanDefinition": scan_definition_name,
            },
            request_type="POST",
            auth_method="basic",
        )

        location = response.headers.get("location")
        scan_id = response.headers.get("x-soda-scan-id")

        if not scan_id or not location:
            raise Exception("Failed to start remote scan")

        return response.headers

    def poll_remote_scan_finished(self, scan_id: str, poll_wait: int = 5, max_retry: int = 100) -> RemoteScanRun | None:
        pass

        result = None
        attempt = 0
        while attempt < max_retry:
            attempt += 1

            self.logs.debug(f"Polling remote scan result attempt {attempt}/{max_retry}.")
            response, json = self.get_remote_scan_status(scan_id)
            if response:
                next_poll_time = response.headers.get("X-Soda-Next-Poll-Time")
                if next_poll_time:
                    poll_wait = (datetime_from_iso_zulu(next_poll_time) - datetime.now(timezone.utc)).seconds
                self.logs.debug(f"Next poll in {poll_wait} seconds.")

                remote_run = self.parse_remote_scan_status(json)
                self.logs.debug(f"Remote scan status: '{remote_run.scan_status.value}'.")

                if remote_run.scan_status in REMOTE_SCAN_FINAL_STATES:
                    result = remote_run
                    break

                if attempt == max_retry:
                    raise Exception(
                        f"Remote scan did not finish in {max_retry} attempts. Last status: {remote_run.scan_status}"
                    )

                sleep(poll_wait)
            else:
                raise Exception(f"Failed to poll remote scan status. Response: {response}")

        return result

    def get_remote_scan_run(self, scan_id: str) -> RemoteScanRun:
        _, json = self.get_remote_scan_status(scan_id)
        return self.parse_remote_scan_status(json)

    def get_remote_scan_status(self, scan_id: str) -> tuple[Response, dict] | None:
        return self._execute_request(
            f"v1/scans/{scan_id}",
            "remote-scan-poll-result",
            request_body=None,
            request_data=None,
            request_type="GET",
            auth_method="basic",
        )

    def parse_remote_scan_status(self, response: dict) -> RemoteScanRun:
        from soda.cloud.remote_scan_run import RemoteScanRun

        if "state" in response:
            state = REMOTE_SCAN_CLOUD_MAPPING.get(response["state"])
            if not state:
                raise Exception(f"Unsupported remote scan state: {response['state']}")

            scan_run_arguments = {
                "scan_id": response["id"],
                "scan_status": state,
                "cloud_url": response.get("cloudUrl"),
                "scan_result": None,
                "created": datetime_from_iso_zulu(response.get("created")) if response.get("created") else None,
                "started": datetime_from_iso_zulu(response.get("started")) if response.get("started") else None,
                "ended": datetime_from_iso_zulu(response.get("ended")) if response.get("ended") else None,
                "submitted": (datetime_from_iso_zulu(response.get("submitted")) if response.get("submitted") else None),
                "scan_time": (datetime_from_iso_zulu(response.get("scanTime")) if response.get("scanTime") else None),
            }

            if state in REMOTE_SCAN_COMPLETED_STATES:
                scan_run_arguments["scan_result"] = ScanResult.from_remote_scan_result_dict(response)

            result = RemoteScanRun(**scan_run_arguments)
        else:
            raise Exception(f"Unknown remote scan state. Response: {response}")

        return result

    def get_remote_scan_logs(self, scan_id: str):
        is_last_page = False
        logs = []

        while not is_last_page:
            _, json = self._execute_request(
                f"v1/scans/{scan_id}/logs",
                "remote-scan-logs",
                request_body=None,
                request_data=None,
                request_type="GET",
                auth_method="basic",
            )
            if "last" in json:
                is_last_page = json["last"]

            if "content" in json:
                logs += json["content"]
        return logs

    def parse_remote_logs(self, logs):
        parsed_logs = []
        for log_dict in logs:
            log = Log.from_dict(log_dict)

            parsed_logs.append(log)

        return parsed_logs

    def delete_remote_scan(self, scan_id: str):
        return self._execute_request(
            f"v1/scans/{scan_id}",
            "remote-scan-delete",
            request_body=None,
            request_data=None,
            request_type="DELETE",
            auth_method="basic",
        )

    def get_check_identities(self, check_id: str) -> dict:
        payload = {"type": "sodaCoreCheckIdentities", "checkId": check_id}

        return self._execute_query(
            payload,
            query_name="get_check_identity",
        )

    def _get_historic_changes_over_time(self, hd: HistoricChangeOverTimeDescriptor):
        query = {
            "type": "sodaCoreHistoricMeasurements",
            "filter": {
                "type": "and",
                "andExpressions": [
                    {
                        "type": "equals",
                        "left": {"type": "columnValue", "columnName": "metric.identity"},
                        "right": {"type": "string", "value": hd.metric_identity},
                    }
                ],
            },
        }

        previous_time_start = None
        previous_time_end = None
        today = date.today()

        if hd.change_over_time_cfg.same_day_last_week:
            last_week = today - timedelta(days=7)
            previous_time_start = datetime(
                year=last_week.year, month=last_week.month, day=last_week.day, tzinfo=timezone.utc
            )
            previous_time_end = datetime(
                year=last_week.year,
                month=last_week.month,
                day=last_week.day,
                hour=23,
                minute=59,
                second=59,
                tzinfo=timezone.utc,
            )

        if previous_time_start and previous_time_end:
            query["filter"]["andExpressions"].append(
                {
                    "type": "greaterThanOrEqual",
                    "left": {"type": "columnValue", "columnName": "measurement.dataTime"},
                    "right": {"type": "time", "scanTime": False, "time": previous_time_start.isoformat()},
                }
            )
            query["filter"]["andExpressions"].append(
                {
                    "type": "lessThanOrEqual",
                    "left": {"type": "columnValue", "columnName": "measurement.dataTime"},
                    "right": {"type": "time", "scanTime": False, "time": previous_time_end.isoformat()},
                }
            )

        return self._execute_query(
            query,
            query_name="get_hisoric_changes_over_time",
        )

    def _get_historic_measurements(self, hd: HistoricMeasurementsDescriptor):
        historic_measurements = self._execute_query(
            {
                "type": "sodaCoreHistoricMeasurements",
                "limit": hd.limit,
                "filter": {
                    "type": "and",
                    "andExpressions": [
                        {
                            "type": "equals",
                            "left": {"type": "columnValue", "columnName": "metric.identity"},
                            "right": {"type": "string", "value": hd.metric_identity},
                        }
                    ],
                },
            },
            query_name="get_hisotric_check_results",
        )
        # Filter out historic_measurements not having 'value' key
        historic_measurements["results"] = [
            measurement for measurement in historic_measurements["results"] if "value" in measurement
        ]
        return historic_measurements

    def _get_historic_check_results(self, hd: HistoricCheckResultsDescriptor):
        return self._execute_query(
            {
                "type": "sodaCoreHistoricCheckResults",
                "limit": hd.limit,
                "filter": {
                    "type": "and",
                    "andExpressions": [
                        {
                            "type": "equals",
                            "left": {"type": "columnValue", "columnName": "check.identity"},
                            "right": {"type": "string", "value": hd.check_identity},
                        }
                    ],
                },
            },
            query_name="get_hisotric_check_results",
        )

    def _get_token(self) -> str:
        if not self.token:
            login_response_code, login_response_json = self.login()
            if login_response_code == 401:
                raise AssertionError(f"Soda Cloud login failed {login_response_code}. Invalid credentials.")
            elif login_response_code == 403:
                raise AssertionError(
                    f"Soda Cloud login failed {login_response_code}. You no longer have access to the organization."
                )
            elif login_response_code != 200:
                raise AssertionError(f"Soda Cloud login failed {login_response_code}. Check credentials.")

            self.token = login_response_json.get("token")
            assert self.token, "No token in login response?!"
        return self.token
